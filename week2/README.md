# C1-Project-Week 2 

## Setting up the environment

For this week we need to import the following libraries:
  
```python
from skimage import io
import matplotlib.pyplot as plt
import cv2
import re
import pickle
import os
```
If you don't have Python installed or we don't how how to install it you can check the instructions from Week 1.

## Task 1: Implement 3D / 2D and block and multiresolution histograms

For this task we have implemented 2D Histogram and Multiresolution Histogram. 

- For the 2D Histogram we have chosen to explore all the possible combinations between two color channels. Also, we can use bins. Binning involves dividing the data range into distinct intervals or bins that will guide the resolution, smoothing, interpretation and efficiency.
- In terms of the bins, we have tested 3 cases: small, medium and big values and we plotted using different colormaps such as: cm.jet, cm.hot, BuPu, colors.LogNorm, cm.viridis and by setting a value for the alpha.
- For the color cases, we computed the histogram for red-green channel, red-blue channel, green-blue channel, grayscale and RGB.
- For the multiresolution we have converted the images in HSV colorspace, we have resized them in order to have a fixed size and for the block sizes we are using 32, 16, 8 and 4. 

## Task 2: Test query system using QSD2-W1 (from week1) with Task1 descriptors and evaluate results.

To perform this task, we have used our best method from the previous week, which is Histogram Intersection.It measures the overlap between two histograms. It's used when you want to find how much two histograms overlap. It's a good choice when histograms represent similar data distributions.

```math
\text{Histogram Intersection (Similarity)} = \sum_{i=1}^{n} \min(h_1(i), h_2(i))
```

- Last week we have divided the image in 32 regions, each region having 3 channel colour histograms in 256 bins and all histograms were concatenated.
- This time we are dividing the image in 32 and 16 regions, we compute and concatenate the histograms and we conclude that the best result is when we have 48 bins.
  
After evaluating the results, we can compare them:

| Method                                      | map@1 | map@5 |
|:--------------------------------------------:|-----:|-----:|
| Week 1                                     | 0.46 | 0.54 |
| Week 2 - 2D Green and Blue                 | 0.46 | 0.54 |
| Week 2 - Multiresolution HSV [32, 16, 8, 4] | 0.40  | 0.43 |
| Week 2 - Multiresolution CieLab [64, 32]   | 0.20  | 0.27 |

#### 2D Histogram Channel - QS1D1
| Channel        | map@1 | map@5 |
|:--------------:|-----:|-----:|
| Red - Blue     | 0.16  | 0.26  |
| Red - Green    | 0.43  | 0.47  |
| Green - Blue   | 0.46  | 0.54  |
| Grey Level     | 0.46  | 0.54  |

#### 2D Histogram Channel - QS1D2
| Channel        | map@1 | map@5 |
|:--------------:|-----:|-----:|
| Red - Blue     | 0.16  | 0.26  |
| Red - Green    | 0.43  | 0.47  |
| Green - Blue   | 0.46  | 0.54  |
| Grey Level     | 0.30  | 0.33  |

## Task 3: Detect and remove text from images in QSD1-W2

    – Detect text bounding box
    – Provide bounding box coordinates for evaluation

We have developed a background removal algorithm that comprises three main steps:

1. Image Preprocessing: In this step we have converted the image to grayscale while blocking intermediate grays, retaining strong black and white regions (since text boxes are typically black or white).

2. Morphological Filtering: The primary goal is to remove unnecessary image details and enhance the text. We can achieve that by using:
- TopHat: Preserve small white elements that would otherwise be removed by the opening operation.
- Dilation: Enhance white regions in the image, particularly the text.
- Closing: Eliminate small black elements within the letters.
- Thresholding: Remove grayish whites and retain the most prominent ones.
- Dilation: Sometimes, only a few pixels remain after thresholding.

4. Connected Component Removal: The aim here is to retain the largest connected component.
- Remove white components generated by the image's shapes to prevent them from affecting the text bounding box.
- Adjust the bounding box size, as dilation can sometimes make it larger than necessary.
- Obtain the final processed image.

This algorithm is designed to extract text or content from a background while optimizing the text's legibility and eliminating unwanted artifacts.

## Task 4 : Evaluate text detection using bounding box using IoU metric

IoU (Intersection over Union) is the area of overlap between the predicted segmentation and the ground truth divided by the area of union between the predicted segmentation and the ground truth. 

```math
\text{IOU} = \frac{\text{True Positives}}{\text{True Positives + False Positives + False Negatives}}
```
For this task we get that IoU is 0.57.

## Task 5: Test query system using query set QSD1-W2

| Method                                      | map@1 | map@5 |
|:--------------------------------------------:|-----:|-----:|
| Histogram intersection with multiple levels  | 0.13  | 0.14  |


## Task 6: For QSD2-W2 : Detect all the paintings (max 2 per image)

For this task we had to detect all the paintings (max 2 per image), remove background and text, apply retrieval system, return correspondences for each painting. 
The first step is to find the masks for the images, so it detects whether there are one or two paintings in the image. If there is at least one contour, we extract a bounding box around the first contour, which potentially represent one of the paintings. If there are two contours, it implies the presence of two paintings in the image.
Once that is done, the text bounding boxes are extracted for each of the regions (either 1 or 2)  in order to not take into account those pixels when calculating the histograms.
Then we calculate histograms with multiple levels for this region (that represents one painting). The computed histograms are stored in hist_per_image. The histograms have a determined multilevel value and a determined bin value.
